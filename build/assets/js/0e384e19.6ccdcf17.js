"use strict";(self.webpackChunkdocusaurus_yt_example=self.webpackChunkdocusaurus_yt_example||[]).push([[9671],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>m});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},u="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),u=c(n),h=o,m=u["".concat(l,".").concat(h)]||u[h]||p[h]||r;return n?a.createElement(m,i(i({ref:t},d),{},{components:n})):a.createElement(m,i({ref:t},d))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:o,i[1]=s;for(var c=2;c<r;c++)i[c]=n[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},9881:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var a=n(7462),o=(n(7294),n(3905));const r={sidebar_position:1},i="Introduction",s={unversionedId:"intro",id:"intro",title:"Introduction",description:"Language is at the core of all forms of human and technological communications; it provides the words, semantics and grammar needed to convey ideas and concepts. In the AI world, a language model serves a similar purpose providing a basis to communicate and generate new concepts.",source:"@site/docs/intro.md",sourceDirName:".",slug:"/intro",permalink:"/khacks-gen-ai/docs/intro",draft:!1,editUrl:"https://github.com/facebook/docusaurus/edit/main/website/docs/intro.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"mySidebar",next:{title:"Building Chat Apps with Cohere",permalink:"/khacks-gen-ai/docs/chatbotwithCohert/intro"}},l={},c=[],d={toc:c},u="wrapper";function p(e){let{components:t,...r}=e;return(0,o.kt)(u,(0,a.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"introduction"},"Introduction"),(0,o.kt)("p",null,"Language is at the core of all forms of human and technological communications; it provides the words, semantics and grammar needed to convey ideas and concepts. In the AI world, a language model serves a similar purpose providing a basis to communicate and generate new concepts."),(0,o.kt)("p",null,"I wanna start this session by first asking you, what does ",(0,o.kt)("strong",{parentName:"p"},"LLM mean?"),"\nA large language model (LLM) is a type of artificial intelligence (AI) algorithm that uses deep learning techniques and massively large data sets to understand, summarize, generate and predict new content. The term generative AI also is closely connected with LLMs, which are, in fact, a type of generative AI that has been specifically architected to help generate text-based content."),(0,o.kt)("p",null,"Before I go further, I want you to know about another topic known as NLP. Natural language processing (NLP) in simple terms refers to giving computers the ability to understand text and spoken words in much the\nsame way human beings can.Language models are commonly used in natural language processing (NLP) applications where a user inputs a query in natural language to generate a result. NLP is a broader field than\nLLM, which consists of algorithms and techniques."),(0,o.kt)("p",null,"An LLM is the evolution of the language model concept in AI that\ndramatically expands the data used for training and inference. In turn, it\nprovides a massive increase in the capabilities of the AI model. As you\nknow ,an LLM needs huge amounts of data sets to be trained ,which in\nitself would contain a lot of parameters. Parameters are a machine\nlearning term for the internal variables of the model that are learned during\nthe training process and represent the knowledge the model has\nacquired.Parameters are the .The quality of a language model depends on its\nsize, the amount and diversity of data it was trained on, and the complexity\nof the learning algorithms used during training."),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Alt text",src:n(8422).Z,width:"760",height:"453"})),(0,o.kt)("p",null,"So how does it work?"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Alt text",src:n(9583).Z,width:"756",height:"421"})),(0,o.kt)("p",null,"In the first step, the LLM needs to be trained on a large volume.The training can take multiple steps, usually starting with an unsupervised learning approach. Unstructured data refers to information that lacks a predefined data model or organized structure. This type of data is often more complex and challenging to process and analyze using traditional methods (example: sensor data). The benefit of training on unlabeled data is that there is often vastly more data available. At this stage, the model begins to derive relationships between different words\nand concepts."),(0,o.kt)("p",null,"Step two calls for training and fine-tuning in the form of self-supervised learning. Self-supervised learning for language models (LLM) is a way of training a computer program to understand and generate human-like language without the need for explicit human-labeled examples. In simple terms we give it a lot of text from the internet or other sources. The model learns to predict missing parts of the text, like guessing the next word in a sentence or filling in the blanks. By doing this, the model starts to learn the underlying patterns and relationships in the language."),(0,o.kt)("p",null,'In step three the LLM tries to understand and recognize the relationships and connections between words and concepts using a self-attention mechanism. Instead of focusing on the whole content, the model breaks it into individual parts and tokens. Tokens can be words, characters, subwords, or symbols, depending on the type and the size of the model. Tokenization is the process of splitting the input and output texts into smaller units that can be processed by the LLM AI models. Tokenization can help the model to handle different languages, vocabularies,\nand formats, and to reduce the computational and memory costs.OpenAI uses a subword tokenization method called "Byte-Pair Encoding (BPE)" for its GPT-based models. BPE is a method that merges the most frequently occurring pairs of characters or bytes into a single token, until a certain number of tokens or a vocabulary size is\nreached.'),(0,o.kt)("p",null,"Let me just give you a quick example of this. "),(0,o.kt)("p",null,"*open your chatgpt and write the phrase ",(0,o.kt)("strong",{parentName:"p"},"reverse the word lollipop*")),(0,o.kt)("p",null,"Reason why it doesn\u2019t work the way we want?"),(0,o.kt)("p",null,"What we want is like mirror writing"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Alt text",src:n(1256).Z,width:"697",height:"257"}),"\nBut the reason this happens is because the model is trained on tokens. The word\n\u201clollipop\u201d is broken into three tokens( \u201clol\u201d, \u201cpop\u201d, \u201cli\u201d). It basically reverses the tokens\ninstead of reversing the whole word."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Applications Of LLM")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Text generation. The ability to generate text on any topic that the\nLLM has been trained on is a primary use case.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Translation. For LLMs trained in multiple languages, the ability to\ntranslate from one language to another is a common feature.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Content summary. Summarizing blocks or multiple pages of text is\na useful function of LLMs.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Rewriting content. Rewriting a section of text is another capability.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Classification and categorization. An LLM is able to classify and\ncategorize content.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Sentiment analysis. Most LLMs can be used for sentiment analysis\nto help users to better understand the intent of a piece of content or\na particular response.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Conversational AI and chatbots. LLMs can enable a conversation\nwith a user in a way that is typically more natural than older\ngenerations of AI technologies."))),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Future")),(0,o.kt)("p",null,'Today, chatbots based on LLMs are most commonly used "out of the box" as a text-based, web-chat interface. They\u2019re used in search engines such as Google\u2019s Bard and Microsoft\u2019s Bing (based on ChatGPT) and for automated\nonline customer assistance.The next generation of LLMs will not likely be artificial general intelligence or sentient in any sense of the word, but they will continuously improve and get "smarter."'),(0,o.kt)("p",null,"LLMs will continue to be trained on ever larger sets of data, and that data will increasingly be better filtered for accuracy and potential bias. It's also likely that LLMs of the future will do a better job than the current generation when it comes to providing attribution and better explanations for how a given result was generated."))}p.isMDXComponent=!0},8422:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/introimg1-c1c3b95cf8256c735f9cac55377fa076.png"},9583:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/introimg2-8f4add22b4bb01d6e2526e8def0fbd28.png"},1256:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/introimg3-da5808a89b50c93f3a743e28d4b10b69.png"}}]);